"""Main FastAPI application."""

import base64
import logging
import os
import sys
import time

from fastapi import FastAPI, UploadFile, File, HTTPException

from src.services import analyze_image_with_vision, refine_products
from src.image_preprocess import preprocess_image
from src.gpt_vision import analyze_food

# -----------------------------------
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
# -----------------------------------

app = FastAPI()

import logging
import sys

logging.basicConfig(
    level=logging.INFO,
    stream=sys.stdout,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
)


# -----------------------------------
# –¢–µ—Ö. —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
# -----------------------------------

@app.get("/health")
def health():
    return {"status": "ok"}


# -----------------------------------
# /analyze ‚Äî —Å—Ç–∞—Ä—ã–π –ø–∞–π–ø–ª–∞–π–Ω
# -----------------------------------

@app.post("/analyze")
async def analyze_photo(image: UploadFile = File(None)):
    if not image:
        raise HTTPException(422, "Image field is required")

    if image.content_type not in ["image/jpeg", "image/png"]:
        raise HTTPException(422, "Unsupported format (use jpeg/png)")

    start_time = time.time()
    logging.info(f"[PIPELINE] Starting /analyze endpoint for file: {image.filename}")

    img_bytes = await image.read()
    img_b64 = base64.b64encode(img_bytes).decode("utf-8")

    try:
        # STEP 1 ‚Äî VISION RECOGNITION
        logging.info("[PIPELINE] Step 1: Starting vision recognition")
        vision_json = analyze_image_with_vision(img_b64, image.content_type)
        products = vision_json["products"]
        logging.info(f"[PIPELINE] Step 1: Vision completed, found {len(products)} products")

        # STEP 2 ‚Äî REFINEMENT
        logging.info("[PIPELINE] Step 2: Starting refinement")
        refine_json = refine_products(products)
        logging.info("[PIPELINE] Step 2: Refinement completed")

        # Add processing time
        end_time = time.time()
        refine_json["processing_time_ms"] = round((end_time - start_time) * 1000, 2)
        logging.info(f"[PIPELINE] /analyze completed successfully, time: {refine_json['processing_time_ms']}ms")

        return refine_json
    except Exception as e:
        logging.exception("Error in /analyze")
        raise HTTPException(422, f"Analysis error: {str(e)}")


# -----------------------------------
# /recognize ‚Äî –Ω–æ–≤—ã–π –±—ã—Å—Ç—Ä—ã–π –ø–∞–π–ø–ª–∞–π–Ω
# -----------------------------------

@app.post("/recognize")
async def recognize_food(image: UploadFile = File(None)):
    """
    Optimized endpoint: preprocess ‚Üí single GPT-4o-mini vision call.
    """
    logging.debug("üì∏ /recognize called ‚Äî starting pipeline")

    if not image:
        raise HTTPException(422, "Image field is required")

    if image.content_type not in ["image/jpeg", "image/png"]:
        raise HTTPException(422, "Unsupported format (use jpeg/png)")

    total_start = time.time()
    logging.info(f"[PIPELINE] Starting /recognize endpoint for file: {image.filename}")

    try:
        # –ì–æ—Ç–æ–≤–∏–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
        tmp_dir = "/tmp/preprocess"
        os.makedirs(tmp_dir, exist_ok=True)

        temp_input = os.path.join(tmp_dir, f"input_{time.time()}.jpg")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        content = await image.read()
        with open(temp_input, "wb") as f:
            f.write(content)
        logging.info(f"[PIPELINE] Saved input image: {temp_input}")

        # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å
        preprocess_start = time.time()
        logging.info("[PIPELINE] Step 1: Starting image preprocessing")
        processed_path = preprocess_image(temp_input)
        preprocess_time = time.time() - preprocess_start
        logging.info(f"[PIPELINE] Step 1: Preprocessing completed in {round(preprocess_time * 1000, 2)}ms")

        # GPT-–∞–Ω–∞–ª–∏–∑
        gpt_start = time.time()
        logging.info("[PIPELINE] Step 2: Starting GPT analysis")
        result_json = analyze_food(processed_path)
        gpt_time = time.time() - gpt_start
        logging.info(f"[PIPELINE] Step 2: GPT analysis completed in {round(gpt_time * 1000, 2)}ms, found {len(result_json.get('products', []))} products")

        # –¢–∞–π–º–∏–Ω–≥–∏
        total_time = time.time() - total_start
        result_json["processing_times"] = {
            "preprocessing_ms": round(preprocess_time * 1000, 2),
            "gpt_ms": round(gpt_time * 1000, 2),
            "total_ms": round(total_time * 1000, 2),
        }

        logging.info(f"[PIPELINE] /recognize completed successfully, total time: {round(total_time * 1000, 2)}ms")

        # –ß–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        try:
            os.remove(temp_input)
        except Exception:
            pass

        return result_json

    except Exception as e:
        logging.exception("Error in /recognize")
        raise HTTPException(422, f"Recognition error: {str(e)}")
